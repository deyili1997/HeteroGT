{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bc53801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from heterogt.utils.tokenizer import EHRTokenizer\n",
    "from heterogt.utils.dataset import FineTuneEHRDataset, batcher\n",
    "from heterogt.utils.train import train_with_early_stopping\n",
    "from heterogt.utils.seed import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c42d3e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Random seed set to 123\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af3d65aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d073b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Namespace(\n",
    "    dataset = \"MIMIC-III\",\n",
    "    tasks = [\"death\", \"readmission\", \"stay\", \"next_diag_6m\", \"next_diag_12m\"], \n",
    "    task_index = 2,\n",
    "    token_type = [\"diag\", \"med\", \"lab\", \"pro\"],\n",
    "    special_tokens = [\"[PAD]\"],\n",
    "    batch_size = 32,\n",
    "    lr = 1e-3,\n",
    "    epochs = 500,\n",
    "    early_stop_patience = 5,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbe56943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current task: stay\n"
     ]
    }
   ],
   "source": [
    "full_data_path = f\"./data_process/{config.dataset}-processed/mimic.pkl\"  # for tokenizer\n",
    "curr_task = config.tasks[config.task_index]\n",
    "print(\"Current task:\", curr_task)\n",
    "if curr_task == \"next_diag_6m\":\n",
    "    finetune_data_path = f\"./data_process/{config.dataset}-processed/mimic_nextdiag_6m.pkl\"\n",
    "elif curr_task == \"next_diag_12m\":\n",
    "    finetune_data_path = f\"./data_process/{config.dataset}-processed/mimic_nextdiag_12m.pkl\"\n",
    "else:\n",
    "    finetune_data_path = f\"./data_process/{config.dataset}-processed/mimic_downstream.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57d4378a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max admissions per patient: 8\n"
     ]
    }
   ],
   "source": [
    "ehr_full_data = pickle.load(open(full_data_path, 'rb'))\n",
    "diag_sentences = ehr_full_data[\"ICD9_CODE\"].values.tolist()\n",
    "med_sentences = ehr_full_data[\"NDC\"].values.tolist()\n",
    "lab_sentences = ehr_full_data[\"LAB_TEST\"].values.tolist()\n",
    "pro_sentences = ehr_full_data[\"PRO_CODE\"].values.tolist()\n",
    "age_gender_sentences = [\"[PAD]\"] + [str(c) + \"_\" + gender for c in set(ehr_full_data[\"AGE\"].values.tolist()) for gender in [\"M\", \"F\"]]\n",
    "token_type_sentences = [\"[PAD]\"] + config.token_type\n",
    "max_admissions = ehr_full_data.groupby(\"SUBJECT_ID\")[\"HADM_ID\"].nunique().max()\n",
    "config.max_num_adms = max_admissions\n",
    "print(f\"Max admissions per patient: {config.max_num_adms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8db4baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age and gender vocabulary size: 37\n"
     ]
    }
   ],
   "source": [
    "task_sentences = config.tasks\n",
    "tokenizer = EHRTokenizer(token_type_sentences, age_gender_sentences, task_sentences, diag_sentences, \n",
    "                         med_sentences, lab_sentences, pro_sentences, special_tokens=config.special_tokens)\n",
    "config.label_vocab_size = len(tokenizer.diag_voc.id2word)  # only for diagnosis\n",
    "config.global_vocab_size = len(tokenizer.vocab.id2word)\n",
    "config.age_gender_vocab_size = tokenizer.token_number(\"age_gender\")\n",
    "print(f\"Age and gender vocabulary size: {config.age_gender_vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a50b960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of DEATH in test dataset: 28.648477157360407 %\n",
      "Percentage of READMISSION in test dataset: 40.1491116751269 %\n",
      "Percentage of STAY>7 days in test dataset: 50.58692893401015 %\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data = pickle.load(open(finetune_data_path, 'rb'))\n",
    "# example label percentage\n",
    "print(\"Percentage of DEATH in test dataset:\",\n",
    "      (test_data[\"DEATH\"] == True).mean() * 100, \"%\")\n",
    "\n",
    "print(\"Percentage of READMISSION in test dataset:\",\n",
    "      (test_data[\"READMISSION\"] == 1).mean() * 100, \"%\")\n",
    "\n",
    "print(\"Percentage of STAY>7 days in test dataset:\",\n",
    "      (test_data[\"STAY_DAYS\"] > 7).mean() * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09f0ec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FineTuneEHRDataset(train_data, tokenizer, token_type=config.token_type, task=curr_task)\n",
    "val_dataset = FineTuneEHRDataset(val_data, tokenizer, token_type=config.token_type, task=curr_task)\n",
    "test_dataset = FineTuneEHRDataset(test_data, tokenizer, token_type=config.token_type, task=curr_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d71f325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    collate_fn=batcher(tokenizer, config.task_index, n_token_type=len(config.token_type), is_pretrain = False),\n",
    "    shuffle=True,\n",
    "    batch_size=config.batch_size,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    collate_fn=batcher(tokenizer, config.task_index, n_token_type=len(config.token_type), is_pretrain = False),\n",
    "    shuffle=False,\n",
    "    batch_size=config.batch_size,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    collate_fn=batcher(tokenizer, config.task_index, n_token_type=len(config.token_type), is_pretrain = False),\n",
    "    shuffle=False,\n",
    "    batch_size=config.batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10339a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if curr_task in [\"death\", \"stay\", \"readmission\"]:\n",
    "    eval_metric = \"prauc\"\n",
    "    task_type = \"binary\"\n",
    "    loss_fn = F.binary_cross_entropy_with_logits\n",
    "else:\n",
    "    eval_metric = \"prauc\"\n",
    "    task_type = \"l2r\"\n",
    "    loss_fn = lambda x, y: F.binary_cross_entropy_with_logits(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5717b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape: torch.Size([32, 256])\n",
      "Token Types shape: torch.Size([32, 256])\n",
      "Admission Index shape: torch.Size([32, 256])\n",
      "Age/Sex IDs shape: torch.Size([32, 7])\n",
      "Task Index: 2\n",
      "Labels shape: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "input_ids, token_types, adm_index, age_gender_ids, task_index, labels = next(iter(train_dataloader))\n",
    "print(\"Input IDs shape:\", input_ids.shape)\n",
    "print(\"Token Types shape:\", token_types.shape)\n",
    "print(\"Admission Index shape:\", adm_index.shape)\n",
    "print(\"Age/Sex IDs shape:\", age_gender_ids.shape)\n",
    "print(\"Task Index:\", task_index)\n",
    "print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814e9e16",
   "metadata": {},
   "source": [
    "# Model Walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad8d7e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 1.13.1\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import HeteroData, Batch as HeteroBatch\n",
    "from torch_geometric.nn import HeteroConv, GATConv\n",
    "from heterogt.model.layer import TransformerEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61f4f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiseaseOccHetGNN(nn.Module):\n",
    "    def __init__(self, d_model: int, heads: int = 4, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.act = nn.GELU()\n",
    "\n",
    "        # 第1层\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('visit','contains','occ'): GATConv(d_model, d_model, heads=heads, concat=False, add_self_loops=False),\n",
    "            ('occ','contained_by','visit'): GATConv(d_model, d_model, heads=heads, concat=False, add_self_loops=False),\n",
    "            ('visit','next','visit'):       GATConv(d_model, d_model, heads=heads, concat=False, add_self_loops=False),\n",
    "        }, aggr='mean')\n",
    "\n",
    "        # 第2层\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('visit','contains','occ'): GATConv(d_model, d_model, heads=heads, concat=False, add_self_loops=False),\n",
    "            ('occ','contained_by','visit'): GATConv(d_model, d_model, heads=heads, concat=False, add_self_loops=False),\n",
    "            ('visit','next','visit'):       GATConv(d_model, d_model, heads=heads, concat=False, add_self_loops=False),\n",
    "        }, aggr='mean')\n",
    "        self.lin = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, hg):\n",
    "        # x_dict: {'visit': [N_visit, d], 'occ': [N_occ, d]}\n",
    "        x_dict = {'visit': hg['visit'].x, 'occ': hg['occ'].x}\n",
    "\n",
    "        # 第1层：HeteroConv → Linear → GELU → Dropout\n",
    "        x_dict = self.conv1(x_dict, hg.edge_index_dict)\n",
    "\n",
    "        # 第2层：HeteroConv → Linear（末层通常不再加激活/随你需要）\n",
    "        x_dict = self.conv2(x_dict, hg.edge_index_dict)\n",
    "        x_dict = {k: self.lin(v) for k, v in x_dict.items()}\n",
    "\n",
    "        return x_dict  # {'visit': [N_visit, d], 'occ': [N_occ, d]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2177ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-class classification task\n",
    "class MultiPredictionHead(nn.Module):\n",
    "    def __init__(self, hidden_size, label_size):\n",
    "        super(MultiPredictionHead, self).__init__()\n",
    "        self.cls = nn.Sequential(\n",
    "                nn.Linear(hidden_size, hidden_size), \n",
    "                nn.ReLU(), \n",
    "                nn.Linear(hidden_size, label_size)\n",
    "            )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.cls(input)\n",
    "    \n",
    "class BinaryPredictionHead(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BinaryPredictionHead, self).__init__()\n",
    "        self.cls = nn.Sequential(\n",
    "                nn.Linear(hidden_size, hidden_size), \n",
    "                nn.ReLU(), \n",
    "                nn.Linear(hidden_size, 1)\n",
    "            )\n",
    "    def forward(self, input):\n",
    "        return self.cls(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c1bfd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[17, 17, 17, 23]])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_dataset)):\n",
    "    age_gender_ids = train_dataset[i][3]\n",
    "    if len(age_gender_ids[0]) > 3:\n",
    "        print(age_gender_ids)\n",
    "        break\n",
    "exp_i = i\n",
    "id_seq = torch.concat([train_dataset[exp_i][0][0], torch.zeros(5, dtype=train_dataset[exp_i][0][0].dtype)], dim=0)\n",
    "type_seq = torch.concat([train_dataset[exp_i][1][0], torch.zeros(5, dtype=train_dataset[exp_i][1][0].dtype)], dim=0)\n",
    "visit_seq = torch.concat([train_dataset[exp_i][2][0], torch.zeros(5, dtype=train_dataset[exp_i][2][0].dtype)], dim=0)\n",
    "age_sex = torch.concat([train_dataset[exp_i][3][0], torch.zeros(3, dtype=train_dataset[exp_i][3][0].dtype)], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "329e68aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroGT(nn.Module):\n",
    "    def __init__(self, tokenizer, d_model, num_heads, layer_types, max_num_adms, device, task, label_vocab_size):\n",
    "        super(HeteroGT, self).__init__()\n",
    "        self.device = device\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_num_adms = max_num_adms\n",
    "        self.global_vocab_size = len(self.tokenizer.vocab.word2id)\n",
    "        self.age_gender_vocab_size = len(self.tokenizer.age_gender_voc.word2id)\n",
    "        self.n_type = len(self.tokenizer.token_type_voc.word2id)\n",
    "        self.d_model = d_model\n",
    "        self.num_attn_heads = num_heads\n",
    "        self.layer_types = layer_types\n",
    "        self.seq_pad_id = tokenizer.convert_tokens_to_ids([\"[PAD]\"], voc_type=\"all\")[0] #0\n",
    "        self.type_pad_id = tokenizer.convert_tokens_to_ids([\"[PAD]\"], voc_type=\"type\")[0] #0\n",
    "        self.adm_pad_id = 0\n",
    "        self.age_gender_pad_id = tokenizer.convert_tokens_to_ids([\"[PAD]\"], voc_type=\"age_gender\")[0] #0\n",
    "        self.node_type_id_dict = {'diag': 1, 'med': 2, 'lab': 3, 'pro': 4, 'visit': 5}\n",
    "        self.graph_node_types = ['diag']\n",
    "        \n",
    "        # embedding layers\n",
    "        self.token_emb = nn.Embedding(self.global_vocab_size, d_model, padding_idx=self.seq_pad_id) # already contains [PAD]\n",
    "        self.type_emb = nn.Embedding(self.n_type + 1, d_model, padding_idx=self.type_pad_id) # n_type already have PAD, + 1 for visit\n",
    "        self.adm_index_emb = nn.Embedding(self.max_num_adms + 1, d_model, padding_idx=self.adm_pad_id) # +1 for pad\n",
    "        self.age_gender_emb = nn.Embedding(self.age_gender_vocab_size, d_model, padding_idx=self.age_gender_pad_id) # already contains [PAD]\n",
    "        self.task_emb = nn.Embedding(5, d_model, padding_idx=None)  # 5 task in total, task embedding\n",
    "        \n",
    "        # stack together\n",
    "        self.stack_layers = nn.ModuleList(self.make_gnn_layer() if layer_type == 'gnn' else self.make_tf_layer()\n",
    "            for layer_type in self.layer_types\n",
    "        )\n",
    "\n",
    "        # prediction head\n",
    "        if task in [\"death\", \"stay\", \"readmission\"]:\n",
    "            self.cls_head = BinaryPredictionHead(self.d_model)\n",
    "        else:\n",
    "            self.cls_head = MultiPredictionHead(self.d_model, label_vocab_size)\n",
    "\n",
    "    def make_tf_layer(self):\n",
    "        assert self.d_model % self.num_attn_heads == 0, \"Invalid model and attention head dimensions\"\n",
    "        layer_layer = nn.TransformerEncoderLayer(d_model=self.d_model, nhead=self.num_attn_heads, batch_first=True, norm_first=True)\n",
    "        tf_wrapper = nn.TransformerEncoder(layer_layer, num_layers=1, enable_nested_tensor=False)\n",
    "        return tf_wrapper\n",
    "\n",
    "    def make_gnn_layer(self):\n",
    "        return DiseaseOccHetGNN(d_model=self.d_model, heads=self.num_attn_heads)\n",
    "    \n",
    "    def forward(self, input_ids, token_types, adm_index, age_gender_ids, task_id):\n",
    "        \"\"\"Forward pass for the model.\n",
    "\n",
    "        Args:\n",
    "            input_ids (Tensor): Input token IDs. Shape of [B, L]\n",
    "            token_types (Tensor): Token type IDs. Shape of [B, L]\n",
    "            adm_index (Tensor): Admission index IDs. Shape of [B, L]\n",
    "            age_gender_ids (Tensor): Age and gender IDs. Shape of [B, V]\n",
    "            task_id (Tensor): Task ID. Shape of [1]\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output logits. Shape of [B, label_size]\n",
    "        \"\"\"\n",
    "        B, L = input_ids.shape\n",
    "        V = age_gender_ids.shape[1]\n",
    "        num_visits = adm_index.max(dim=1).values\n",
    "        \n",
    "        task_id = torch.full((B,), task_id, dtype=torch.long, device=self.device) # [1] -> [B]\n",
    "        # 基础表示\n",
    "        task_id_embed = self.task_emb(task_id).unsqueeze(1) # [B, 1, d]\n",
    "        seq_embed = self.token_emb(input_ids)  # [B, L, d]\n",
    "        visit_embed = self.age_gender_emb(age_gender_ids) #[B, V, d], the virtual node representation in gnn\n",
    "\n",
    "        # run through layers\n",
    "        for i, layer_type in enumerate(self.layer_types):\n",
    "            if layer_type == 'gnn':\n",
    "                hg_batch = self.build_graph_batch(seq_embed, token_types, self.graph_node_types, visit_embed, adm_index) # num_visits is a 1d tensor of [B]\n",
    "                gnn_out = self.stack_layers[i](hg_batch)['visit']  # extract virtual visit node representations\n",
    "                visit_embed = self.process_gnn_out(gnn_out, num_visits, V) # [B, V, d]\n",
    "            elif layer_type == 'tf':\n",
    "                x, src_key_padding_mask, attn_mask = self.prepare_tf_input(task_id_embed, seq_embed, visit_embed, i, input_ids, \n",
    "                                                                            adm_index, token_types, num_visits)\n",
    "                h = self.stack_layers[i](src=x, src_key_padding_mask=src_key_padding_mask, mask=attn_mask) # [B, 1+L+V, d]\n",
    "                task_id_embed, seq_embed, visit_embed = self.process_tf_out(h, L, V) # # [B, 1, d], [B, L, d], [B, V, d]\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown layer type: {layer_type}\")\n",
    "\n",
    "        logits = self.cls_head(task_id_embed.squeeze())  # [B, label_size]\n",
    "        return logits\n",
    "\n",
    "    def build_graph_batch(self, seq_embed, token_types, graph_node_types, visit_embed, adm_index):\n",
    "        \"\"\"Build a batch of heterogeneous graphs from the input sequences.\n",
    "\n",
    "        Args:\n",
    "            seq_embed (Tensor): Sequence embeddings. Shape of [B, L, d]\n",
    "            token_types (Tensor): Token type IDs. Shape of [B, L]\n",
    "            graph_node_types: a list controls what types of tokens are connected to the virtual visit nodes. e.g. ['diag']\n",
    "            visit_embed (Tensor): Visit embeddings. Shape of [B, V, d]\n",
    "        Returns:\n",
    "            A batch of heterogeneous graphs.\n",
    "        \"\"\"\n",
    "        B, L = seq_embed.shape[0], seq_embed.shape[1]\n",
    "        V = visit_embed.shape[1]\n",
    "        graph_node_type_ids = [self.node_type_id_dict[t] for t in graph_node_types]\n",
    "        graphs = [] # contains heterogeneous graphs for each patient\n",
    "        for p in range(B):\n",
    "            hg_p = self.build_patient_graph(seq_embed[p], token_types[p], visit_embed[p], adm_index[p], graph_node_type_ids)\n",
    "            graphs.append(hg_p)\n",
    "        hg_batch = HeteroBatch.from_data_list(graphs).to(self.device)\n",
    "        return hg_batch\n",
    "\n",
    "    def build_patient_graph(self, seq_embed_p, token_types_p, visit_embed_p, adm_index_p, graph_node_type_ids):\n",
    "        \"\"\"Build a heterogeneous graph for a single patient.\n",
    "\n",
    "        Args:\n",
    "            seq_embed_p (Tensor): Sequence embeddings for patient p. Shape [L, d]\n",
    "            token_types_p (Tensor): Token type IDs for patient p. Shape [L]\n",
    "            visit_embed_p (Tensor): Visit embeddings for patient p. Shape [V, d]\n",
    "            graph_node_type_ids (list): List of graph node type IDs that the graph uses.\n",
    "            adm_index_p (Tensor): Admission index for patient p. Shape [L]\n",
    "\n",
    "        Returns:\n",
    "            A heterogeneous graph for patient p.\n",
    "        \"\"\"\n",
    "        hg = HeteroData()\n",
    "        occ_mask = torch.isin(token_types_p, torch.tensor(graph_node_type_ids, device=token_types_p.device)) # [L], a mask for the token types needed in the graph\n",
    "        occ_pos = torch.nonzero(occ_mask, as_tuple=False).view(-1) # [L], seq position index for the token types needed in the graph\n",
    "        num_occ = occ_pos.numel() # int, number of occurrences of the token types needed in the graph\n",
    "        \n",
    "        # build visit virtual nodes\n",
    "        nonpad = adm_index_p != self.adm_pad_id\n",
    "        adm_index_used_p = adm_index_p[nonpad] # adm_index非pad部分\n",
    "        adm_ids_unique, adm_lid_nonpad = torch.unique(adm_index_used_p, return_inverse=True)\n",
    "        num_visit_p = adm_ids_unique.numel()  # int, number of visits for patient\n",
    "        adm_lid_full = torch.full_like(token_types_p, fill_value=-1) # [L]\n",
    "        adm_lid_full[nonpad] = adm_lid_nonpad\n",
    "        hg['visit'].x = visit_embed_p[:num_visit_p, :]\n",
    "        hg['visit'].num_nodes = num_visit_p\n",
    "        \n",
    "        # build medical code nodes\n",
    "        gid_occ_embed = seq_embed_p[occ_pos, :]\n",
    "        hg['occ'].x = gid_occ_embed\n",
    "        hg['occ'].num_nodes = num_occ\n",
    "\n",
    "        # build edges between occ nodes and virtual visit nodes\n",
    "        occ_adm_lid = adm_lid_full[occ_pos]\n",
    "        assert (occ_adm_lid != -1).all(), \"occ_adm_lid contains -1\"\n",
    "        e_v2o = torch.stack([occ_adm_lid, torch.arange(num_occ, device=self.device)], dim=0)\n",
    "        e_o2v = torch.stack([torch.arange(num_occ, device=self.device), occ_adm_lid], dim=0)\n",
    "        hg['visit','contains','occ'].edge_index = e_v2o\n",
    "        hg['occ','contained_by','visit'].edge_index = e_o2v\n",
    "        \n",
    "        # build forward edges between virtual visit nodes\n",
    "        if num_visit_p > 1:\n",
    "            src = torch.arange(0, num_visit_p - 1, device=self.device)\n",
    "            dst = torch.arange(1, num_visit_p, device=self.device)\n",
    "            e_next = torch.stack([src, dst], dim=0) # [2, num_visit_p-1]\n",
    "        else:\n",
    "            e_next = torch.empty(2, 0, dtype=torch.long, device=self.device)\n",
    "        hg['visit','next','visit'].edge_index = e_next\n",
    "        return hg\n",
    "\n",
    "    def process_gnn_out(self, gnn_out, num_visits, V):\n",
    "        \"\"\"Process the output of the GNN layer.\n",
    "\n",
    "        Args:\n",
    "            gnn_out (Tensor): The output of the GNN layer. Shape [sum(num_visits), d]\n",
    "            num_visits (Tensor): A tensor containing the number of visits for each patient.\n",
    "            V (int): The maximum number of visits.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: The processed visit embeddings. Shape [B, V, d]\n",
    "        \"\"\"\n",
    "        B = len(num_visits)\n",
    "        # 计算每个批次的累积偏移量\n",
    "        cumsum = torch.cumsum(num_visits, dim=0)  # [B]\n",
    "        offsets = torch.cat([torch.tensor([0], device=self.device), cumsum[:-1]])  # [B]\n",
    "\n",
    "        # 创建索引以从 gnn_out 中提取所有批次的嵌入\n",
    "        indices = torch.arange(sum(num_visits), device=self.device)  # [N]\n",
    "        batch_indices = torch.repeat_interleave(torch.arange(B, device=self.device), num_visits)  # [N]\n",
    "        visit_pos = indices - offsets[batch_indices]  # [N]，每个嵌入的相对位置\n",
    "\n",
    "        # 创建目标张量 visit_emb_pad，初始化为零\n",
    "        visit_emb_pad = torch.zeros(B, V, self.d_model, device=self.device, dtype=gnn_out.dtype)  # [B, V, d]\n",
    "\n",
    "        # 创建掩码，选择有效位置 (visit_pos < V 且 visit_pos < num_visits)\n",
    "        mask = (visit_pos < V) & (visit_pos < num_visits[batch_indices])  # [N]\n",
    "        valid_indices = indices[mask]  # [N_valid]\n",
    "        valid_batch_indices = batch_indices[mask]  # [N_valid]\n",
    "        valid_visit_pos = visit_pos[mask]  # [N_valid]\n",
    "\n",
    "        # 使用 scatter 将 gnn_out 的值分配到 visit_emb_pad\n",
    "        visit_emb_pad[valid_batch_indices, valid_visit_pos] = gnn_out[valid_indices]\n",
    "        return visit_emb_pad\n",
    "    \n",
    "    def prepare_tf_input(self, task_id_embed, seq_embed, visit_embed, layer_i, input_ids, adm_index, token_types, num_visits):\n",
    "        \"\"\"Prepare the input for the Transformer layer.\n",
    "        Args:\n",
    "            task_id_emb (Tensor): Task ID embeddings. Shape [B, 1, d]\n",
    "            seq_embed (Tensor): Sequence embeddings. Shape [B, L, d]\n",
    "            visit_embed (Tensor): Visit embeddings. Shape [B, V, d]\n",
    "            layer_i (int): The current layer index.\n",
    "            adm_index (tensor): The admission index. Shape [B, L]\n",
    "            token_types (Tensor): Token types. Shape [B, L]\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Tensor, Tensor, Tensor]: Processed inputs for the Transformer layer.\n",
    "        \"\"\"\n",
    "        \n",
    "        B, L, d = seq_embed.shape\n",
    "        V = visit_embed.shape[1]\n",
    "\n",
    "        # Part 1: prepare main seq embedding x\n",
    "        # important: initiate new tensor to ensure safe autograd\n",
    "        x = torch.empty(B, 1 + L + V, d, device=seq_embed.device, dtype=seq_embed.dtype)\n",
    "        x[:, 0:1, :] = task_id_embed\n",
    "        x[:, 1:1 + L, :] = seq_embed\n",
    "        x[:, 1 + L:, :] = visit_embed\n",
    "        \n",
    "        # we already have token_types for main seq, just prepare token types for visit nodes\n",
    "        # here it is out of the if branch because it is needed in the mask making\n",
    "        arange_V = torch.arange(1, V + 1, device=self.device, dtype=torch.long)[None, :]  # [1, V]\n",
    "        n_v = num_visits.view(B, 1)  # [B, 1]\n",
    "        visit_index = torch.where(arange_V <= n_v, arange_V, torch.full((B, V), self.adm_pad_id, device=self.device, dtype=torch.long))  # [B, V]\n",
    "        visit_type_id = torch.full((B, V), self.node_type_id_dict['visit'], dtype=torch.long, device=self.device)  # [B, V]\n",
    "        visit_type_id_mask = (visit_index != self.adm_pad_id).long() # [B, V]\n",
    "        visit_type_id = visit_type_id * visit_type_id_mask # [B, V]\n",
    "        token_types = torch.cat([token_types, visit_type_id], dim=1)  # [B, L+V]\n",
    "\n",
    "        # if it is the first time transformer going through, we need extra information of admission index and token types\n",
    "        if (layer_i == 0) or (layer_i == 1 and self.layer_types[0] == 'gnn'):\n",
    "            adm_index = torch.cat([adm_index, visit_index], dim=1)  # [B, L+V]\n",
    "            # transform into embedding and add\n",
    "            adm_index_embed = self.adm_index_emb(adm_index)\n",
    "            token_type_embed = self.type_emb(token_types)\n",
    "            x_non_task = x[:, 1:, :]\n",
    "            x_non_task.add_(adm_index_embed).add_(token_type_embed)\n",
    "            x[:, 1:, :] = x_non_task\n",
    "        else:\n",
    "            x = x\n",
    "            \n",
    "        # part 2: prepare mask (src_key_padding_mask and attn_mask)\n",
    "        task_pad_mask = torch.zeros((B, 1), dtype=torch.bool, device=self.device) # [B, 1]\n",
    "        seq_pad_mask = (input_ids == self.seq_pad_id) # [B, L], bool\n",
    "        visit_pad_mask = (visit_index == self.adm_pad_id) # [B, V], bool\n",
    "        src_key_padding_mask = torch.cat([task_pad_mask, seq_pad_mask, visit_pad_mask], dim=1)  # [B, 1+L+V]\n",
    "        attn_mask = self.build_attn_mask(torch.cat([torch.full((B, 1), -1, device=self.device), token_types], dim=1), forbid_map=None, num_heads=self.num_attn_heads)\n",
    "        assert attn_mask.dtype == src_key_padding_mask.dtype, f\"attn_mask dtype ({attn_mask.dtype}) and src_key_padding_mask dtype ({src_key_padding_mask.dtype}) must match\"\n",
    "        return x, src_key_padding_mask, attn_mask\n",
    "    \n",
    "    def process_tf_out(self, h, L, V):\n",
    "        return h[:, 0:1, :], h[:, 1:1 + L, :], h[:, 1 + L:, :]  # [B, 1, d], [B, L, d], [B, V, d]\n",
    "        \n",
    "    @staticmethod\n",
    "    def build_attn_mask(token_types, forbid_map, num_heads):\n",
    "        B, L = token_types.shape\n",
    "        device = token_types.device\n",
    "        \n",
    "        if forbid_map == None:\n",
    "            mask = torch.zeros((B, L, L), dtype=torch.bool, device=device)\n",
    "        else:\n",
    "            # 收集所有出现的 token 类型\n",
    "            observed = torch.unique(token_types)\n",
    "            for q_t, ks in forbid_map.items():\n",
    "                observed = torch.unique(torch.cat([observed, torch.tensor([q_t] + list(ks), device=device)]))\n",
    "            type_list = observed.sort().values\n",
    "            t2i = {t.item(): i for i, t in enumerate(type_list)}  # Map token types to indices\n",
    "            T = len(type_list)\n",
    "\n",
    "            # 构造禁止矩阵 (T, T)，单向关系\n",
    "            ban_table = torch.zeros((T, T), dtype=torch.bool, device=device)\n",
    "            for q_t, ks in forbid_map.items():\n",
    "                if q_t in t2i:\n",
    "                    qi = t2i[q_t]\n",
    "                    for k_t in ks:\n",
    "                        if k_t in t2i:\n",
    "                            ban_table[qi, t2i[k_t]] = True  # 只设置 q -> k 的禁止\n",
    "\n",
    "            # 向量化映射 token_types 到类型索引\n",
    "            mapping = torch.zeros_like(type_list, dtype=torch.long, device=device)\n",
    "            for t, i in t2i.items():\n",
    "                mapping[type_list == t] = i\n",
    "            q_idx = mapping[torch.searchsorted(type_list, token_types.unsqueeze(-1))]\n",
    "            k_idx = mapping[torch.searchsorted(type_list, token_types.unsqueeze(-2))]\n",
    "\n",
    "            # 查询 ban_table 得到 (B, L, L)\n",
    "            mask = ban_table[q_idx, k_idx].to(torch.bool)\n",
    "        \n",
    "        # 扩展到 num_heads\n",
    "        mask = mask.unsqueeze(1).expand(B, num_heads, L, L)\n",
    "        mask = mask.reshape(B * num_heads, L, L)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71c2fed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 001: 100%|██████████| 98/98 [00:03<00:00, 26.99it/s, loss=0.6870]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 55.10it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 54.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.6437924345280218, 'recall': 0.8325493885204374, 'f1': 0.7261041930833033, 'auc': 0.756861614475183, 'prauc': 0.7314555103458248}\n",
      "Test:      {'precision': 0.6397500600801737, 'recall': 0.8347444339892294, 'f1': 0.7243537365820711, 'auc': 0.7450262665553289, 'prauc': 0.7220247910309557}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 002: 100%|██████████| 98/98 [00:03<00:00, 29.24it/s, loss=0.5978]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 51.05it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 55.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.6728849185478905, 'recall': 0.8030730636538004, 'f1': 0.7322373074027836, 'auc': 0.7925261047844596, 'prauc': 0.8077377834991725}\n",
      "Test:      {'precision': 0.6614173228329097, 'recall': 0.7902163687651609, 'f1': 0.7201028668761388, 'auc': 0.7835963008878333, 'prauc': 0.8026325372736457}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 003: 100%|██████████| 98/98 [00:03<00:00, 29.58it/s, loss=0.5438]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 55.33it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 54.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7745706978415252, 'recall': 0.6647851991198972, 'f1': 0.7154910513884695, 'auc': 0.8160437960149983, 'prauc': 0.8204824995825031}\n",
      "Test:      {'precision': 0.7545293072797352, 'recall': 0.6660395108163498, 'f1': 0.7075283094740732, 'auc': 0.8017717404380125, 'prauc': 0.8142003155344855}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 004: 100%|██████████| 98/98 [00:03<00:00, 28.15it/s, loss=0.5230]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 55.17it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 54.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.750895473784595, 'recall': 0.7231106930049448, 'f1': 0.7367412090569309, 'auc': 0.8195792087688486, 'prauc': 0.8221592157973597}\n",
      "Test:      {'precision': 0.7480694980670912, 'recall': 0.7290686735630948, 'f1': 0.7384468744648945, 'auc': 0.8143950387241052, 'prauc': 0.8263494259189552}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 005: 100%|██████████| 98/98 [00:03<00:00, 29.46it/s, loss=0.4731]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 54.99it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 54.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.6884447860602397, 'recall': 0.8425838820920584, 'f1': 0.7577552121946224, 'auc': 0.8250878214110925, 'prauc': 0.8351096417501299}\n",
      "Test:      {'precision': 0.6783431347464118, 'recall': 0.831922232672211, 'f1': 0.7473239387115712, 'auc': 0.8190295996420279, 'prauc': 0.8341726642396683}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 006: 100%|██████████| 98/98 [00:03<00:00, 29.34it/s, loss=0.4360]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 54.79it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 50.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7672872340400024, 'recall': 0.7237378488531712, 'f1': 0.7448765481727507, 'auc': 0.8321783397329956, 'prauc': 0.8420200981074151}\n",
      "Test:      {'precision': 0.7667997338630512, 'recall': 0.7227971150808317, 'f1': 0.744148501862332, 'auc': 0.8301147050933007, 'prauc': 0.8427487468335182}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 007: 100%|██████████| 98/98 [00:03<00:00, 28.92it/s, loss=0.4123]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 52.65it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 53.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.6957210776526791, 'recall': 0.825964252114061, 'f1': 0.7552688122387651, 'auc': 0.821758429654806, 'prauc': 0.8328849547522609}\n",
      "Test:      {'precision': 0.6884249471440581, 'recall': 0.8168704923147794, 'f1': 0.7471676416712909, 'auc': 0.8181531921276337, 'prauc': 0.8345096316731729}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 008: 100%|██████████| 98/98 [00:03<00:00, 29.09it/s, loss=0.3904]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 54.44it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 54.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7331737959894311, 'recall': 0.7685794920013529, 'f1': 0.7504592724040332, 'auc': 0.8232297642016588, 'prauc': 0.8322767578748171}\n",
      "Test:      {'precision': 0.7338563669259691, 'recall': 0.7626215114432029, 'f1': 0.7479624738554598, 'auc': 0.8203744613682568, 'prauc': 0.8334315820749832}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 009: 100%|██████████| 98/98 [00:03<00:00, 29.36it/s, loss=0.3637]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 54.64it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 55.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7240981240960344, 'recall': 0.7867670115999161, 'f1': 0.7541328474259331, 'auc': 0.8217928418428897, 'prauc': 0.8280173468259712}\n",
      "Test:      {'precision': 0.7240476882793718, 'recall': 0.780809031041766, 'f1': 0.7513578706837842, 'auc': 0.8234740507976104, 'prauc': 0.8359447322705349}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 010: 100%|██████████| 98/98 [00:03<00:00, 29.46it/s, loss=0.3448]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 55.24it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 54.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7384568651253388, 'recall': 0.7623079335190897, 'f1': 0.7501928664693999, 'auc': 0.8221515323872945, 'prauc': 0.8340242752713076}\n",
      "Test:      {'precision': 0.7311504956421414, 'recall': 0.7632486672914292, 'f1': 0.7468548584550627, 'auc': 0.8172349071119775, 'prauc': 0.8331543630271326}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 011: 100%|██████████| 98/98 [00:03<00:00, 28.61it/s, loss=0.3231]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 51.12it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 55.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.6929217668954419, 'recall': 0.8165569143906662, 'f1': 0.7496761142195235, 'auc': 0.8131560859486846, 'prauc': 0.8207518497081199}\n",
      "Test:      {'precision': 0.693964371176033, 'recall': 0.8184383819353451, 'f1': 0.7510791317223544, 'auc': 0.8151422903872512, 'prauc': 0.8280447116813429}\n",
      "\n",
      "Early stopping triggered (no improvement for 5 epochs).\n",
      "\n",
      "Best validation performance:\n",
      "{'precision': 0.7672872340400024, 'recall': 0.7237378488531712, 'f1': 0.7448765481727507, 'auc': 0.8321783397329956, 'prauc': 0.8420200981074151}\n",
      "Corresponding test performance:\n",
      "{'precision': 0.7667997338630512, 'recall': 0.7227971150808317, 'f1': 0.744148501862332, 'auc': 0.8301147050933007, 'prauc': 0.8427487468335182}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 001: 100%|██████████| 98/98 [00:03<00:00, 29.57it/s, loss=0.6862]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 55.24it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 54.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.8233650083799701, 'recall': 0.4619002822186833, 'f1': 0.5918039327173215, 'auc': 0.7736148240271222, 'prauc': 0.7909020338803208}\n",
      "Test:      {'precision': 0.824411134899227, 'recall': 0.48291000313426496, 'f1': 0.6090567483543982, 'auc': 0.7697587060657446, 'prauc': 0.7876225339272951}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 002: 100%|██████████| 98/98 [00:03<00:00, 29.25it/s, loss=0.5777]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 55.39it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 55.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.8864902506902056, 'recall': 0.3991846973960515, 'f1': 0.5504864822024136, 'auc': 0.8060733543262751, 'prauc': 0.8217608776486537}\n",
      "Test:      {'precision': 0.8851035404082492, 'recall': 0.41549074944993575, 'f1': 0.5655142935581282, 'auc': 0.8039277774170541, 'prauc': 0.8194772800791071}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 003: 100%|██████████| 98/98 [00:03<00:00, 29.44it/s, loss=0.5645]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 53.48it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 54.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7861024844689981, 'recall': 0.6349952963291471, 'f1': 0.7025151728511457, 'auc': 0.8118706274542546, 'prauc': 0.8194397443675241}\n",
      "Test:      {'precision': 0.7710298000725349, 'recall': 0.6409532768872971, 'f1': 0.6999999950400363, 'auc': 0.8052551734065786, 'prauc': 0.817061147700396}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 004: 100%|██████████| 98/98 [00:03<00:00, 29.58it/s, loss=0.5183]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 51.19it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 55.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7313387730410054, 'recall': 0.7588585763538449, 'f1': 0.7448445625586618, 'auc': 0.8147214134939382, 'prauc': 0.8208960295413035}\n",
      "Test:      {'precision': 0.7219298245592927, 'recall': 0.7742238946353898, 'f1': 0.747162954604392, 'auc': 0.8189720684113276, 'prauc': 0.8270063022622547}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 005: 100%|██████████| 98/98 [00:03<00:00, 29.49it/s, loss=0.4849]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 54.77it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 55.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7851420247604328, 'recall': 0.6760740043879709, 'f1': 0.726537484494659, 'auc': 0.8256758428147702, 'prauc': 0.8327173641328465}\n",
      "Test:      {'precision': 0.7705210563855442, 'recall': 0.6770147381603104, 'f1': 0.7207477833676482, 'auc': 0.8224512733629394, 'prauc': 0.8329315077159989}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 006: 100%|██████████| 98/98 [00:03<00:00, 29.49it/s, loss=0.4448]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 55.38it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 54.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7510772290329762, 'recall': 0.7105675760404184, 'f1': 0.7302610327069335, 'auc': 0.8101638331620762, 'prauc': 0.8160163880678859}\n",
      "Test:      {'precision': 0.7395561357678213, 'recall': 0.7105675760404184, 'f1': 0.7247721043871741, 'auc': 0.8087568271148767, 'prauc': 0.8169699100852921}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 007: 100%|██████████| 98/98 [00:03<00:00, 28.68it/s, loss=0.4330]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 54.63it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 55.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7172818791926251, 'recall': 0.804327375350253, 'f1': 0.7583148508899525, 'auc': 0.8293437299335498, 'prauc': 0.8372529437521848}\n",
      "Test:      {'precision': 0.7223311852039161, 'recall': 0.8084038883637241, 'f1': 0.7629476126519056, 'auc': 0.8304370410525346, 'prauc': 0.8392810329892688}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 008: 100%|██████████| 98/98 [00:03<00:00, 29.39it/s, loss=0.4254]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 55.27it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 50.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.8008333333299965, 'recall': 0.6026967701454917, 'f1': 0.6877795621038041, 'auc': 0.8069532513690274, 'prauc': 0.8184486208031045}\n",
      "Test:      {'precision': 0.7917189460443675, 'recall': 0.5936030103462101, 'f1': 0.6784946187557426, 'auc': 0.804570133992904, 'prauc': 0.8178082388009109}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 009: 100%|██████████| 98/98 [00:03<00:00, 29.40it/s, loss=0.3736]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 55.28it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 55.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.811889596599525, 'recall': 0.5995609909043601, 'f1': 0.6897546848653519, 'auc': 0.8205274278200587, 'prauc': 0.8151028646479568}\n",
      "Test:      {'precision': 0.8097381342029062, 'recall': 0.6205707118199418, 'f1': 0.7026451220155517, 'auc': 0.8237012563753714, 'prauc': 0.8232290490942189}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 010: 100%|██████████| 98/98 [00:03<00:00, 29.53it/s, loss=0.3592]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 53.62it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 54.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7850098619298422, 'recall': 0.6240200689851866, 'f1': 0.6953179545317454, 'auc': 0.8016193119792896, 'prauc': 0.7937613599943104}\n",
      "Test:      {'precision': 0.772585669778923, 'recall': 0.6221386014405076, 'f1': 0.6892478672114205, 'auc': 0.7982588623513713, 'prauc': 0.7939129466357512}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 011: 100%|██████████| 98/98 [00:03<00:00, 29.21it/s, loss=0.3098]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 55.27it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 55.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7440381558004959, 'recall': 0.7337723424247922, 'f1': 0.7388695876723638, 'auc': 0.8122571491697519, 'prauc': 0.8097990898339629}\n",
      "Test:      {'precision': 0.7342902711300342, 'recall': 0.7218563813084922, 'f1': 0.7280202353522685, 'auc': 0.8070417622374666, 'prauc': 0.8094891109641273}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 012: 100%|██████████| 98/98 [00:03<00:00, 29.61it/s, loss=0.2867]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 55.20it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 54.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7805237919558078, 'recall': 0.6635308874234446, 'f1': 0.7172881306236076, 'auc': 0.8165544527914514, 'prauc': 0.8134237480665958}\n",
      "Test:      {'precision': 0.7790697674390296, 'recall': 0.6723110692986131, 'f1': 0.7217640078170824, 'auc': 0.8152857912960232, 'prauc': 0.8146408267799495}\n",
      "\n",
      "Early stopping triggered (no improvement for 5 epochs).\n",
      "\n",
      "Best validation performance:\n",
      "{'precision': 0.7172818791926251, 'recall': 0.804327375350253, 'f1': 0.7583148508899525, 'auc': 0.8293437299335498, 'prauc': 0.8372529437521848}\n",
      "Corresponding test performance:\n",
      "{'precision': 0.7223311852039161, 'recall': 0.8084038883637241, 'f1': 0.7629476126519056, 'auc': 0.8304370410525346, 'prauc': 0.8392810329892688}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 001: 100%|██████████| 98/98 [00:03<00:00, 29.08it/s, loss=0.6701]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 51.04it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 53.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7981308411177658, 'recall': 0.5355910943852756, 'f1': 0.6410208246152458, 'auc': 0.7907395345000522, 'prauc': 0.7973553807153831}\n",
      "Test:      {'precision': 0.7877713779318221, 'recall': 0.5575415490731969, 'f1': 0.652956293344552, 'auc': 0.7893809830844088, 'prauc': 0.7974087057993914}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 002: 100%|██████████| 98/98 [00:03<00:00, 28.92it/s, loss=0.5739]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 54.90it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 54.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7235724743756264, 'recall': 0.774851050483616, 'f1': 0.748334337826121, 'auc': 0.8161243757955621, 'prauc': 0.8288430788405463}\n",
      "Test:      {'precision': 0.7184073860337034, 'recall': 0.780809031041766, 'f1': 0.7483095367043849, 'auc': 0.8148323364776693, 'prauc': 0.8300032669021539}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 003: 100%|██████████| 98/98 [00:03<00:00, 29.46it/s, loss=0.5328]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 54.86it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 54.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7789272030621497, 'recall': 0.6375039197220523, 'f1': 0.7011553666632225, 'auc': 0.8079005159215901, 'prauc': 0.822820100285046}\n",
      "Test:      {'precision': 0.7807909604490366, 'recall': 0.6500470366865787, 'f1': 0.7094455802549257, 'auc': 0.8128471315169974, 'prauc': 0.8293071948101607}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 004: 100%|██████████| 98/98 [00:03<00:00, 29.23it/s, loss=0.5127]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 54.64it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 55.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7678072625671516, 'recall': 0.6895578551248368, 'f1': 0.7265818552466081, 'auc': 0.808829544526307, 'prauc': 0.8193313950109768}\n",
      "Test:      {'precision': 0.759892689467606, 'recall': 0.7105675760404184, 'f1': 0.7344028470531567, 'auc': 0.8139421375746383, 'prauc': 0.8287256319619588}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 005: 100%|██████████| 98/98 [00:03<00:00, 28.84it/s, loss=0.4828]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 53.51it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 51.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.8122192273099182, 'recall': 0.5669488867965916, 'f1': 0.6677746950633318, 'auc': 0.8040759905510663, 'prauc': 0.8182500444627878}\n",
      "Test:      {'precision': 0.8098681412130588, 'recall': 0.5970523675114549, 'f1': 0.6873646160505501, 'auc': 0.8083876809679341, 'prauc': 0.8236225106552842}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 006: 100%|██████████| 98/98 [00:03<00:00, 29.16it/s, loss=0.4681]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 55.32it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 55.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7303785780217594, 'recall': 0.7441204139205264, 'f1': 0.7371854563215368, 'auc': 0.8053327136125271, 'prauc': 0.8152410617471375}\n",
      "Test:      {'precision': 0.7205266307578679, 'recall': 0.755095641264487, 'f1': 0.737406211506381, 'auc': 0.8081324396110828, 'prauc': 0.8208997784658141}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 007: 100%|██████████| 98/98 [00:03<00:00, 29.57it/s, loss=0.4467]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 55.29it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 54.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7549420586204671, 'recall': 0.6945751019106473, 'f1': 0.7235015465333382, 'auc': 0.8053069923858136, 'prauc': 0.8212585065884452}\n",
      "Test:      {'precision': 0.7418289864617306, 'recall': 0.7046095954822684, 'f1': 0.7227404260077407, 'auc': 0.8063033189429756, 'prauc': 0.8253664093024937}\n",
      "\n",
      "Early stopping triggered (no improvement for 5 epochs).\n",
      "\n",
      "Best validation performance:\n",
      "{'precision': 0.7235724743756264, 'recall': 0.774851050483616, 'f1': 0.748334337826121, 'auc': 0.8161243757955621, 'prauc': 0.8288430788405463}\n",
      "Corresponding test performance:\n",
      "{'precision': 0.7184073860337034, 'recall': 0.780809031041766, 'f1': 0.7483095367043849, 'auc': 0.8148323364776693, 'prauc': 0.8300032669021539}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 001: 100%|██████████| 98/98 [00:03<00:00, 29.38it/s, loss=0.6677]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 54.92it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 53.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.766809172169581, 'recall': 0.6186892442752628, 'f1': 0.6848316507298817, 'auc': 0.7841575127734526, 'prauc': 0.7976663059641764}\n",
      "Test:      {'precision': 0.7581448830940661, 'recall': 0.6202571338958286, 'f1': 0.6823042378900404, 'auc': 0.7836591674732616, 'prauc': 0.8015278716454809}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 002: 100%|██████████| 98/98 [00:03<00:00, 29.10it/s, loss=0.5777]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 55.05it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 54.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7450761798560198, 'recall': 0.628723737846884, 'f1': 0.6819727841491919, 'auc': 0.7833941650392464, 'prauc': 0.7992344613689741}\n",
      "Test:      {'precision': 0.7311827956962137, 'recall': 0.6183756663511497, 'f1': 0.670064555005475, 'auc': 0.7788514088608162, 'prauc': 0.7989141013420193}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 003: 100%|██████████| 98/98 [00:03<00:00, 27.01it/s, loss=0.5726]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 55.01it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 54.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.6857142857124547, 'recall': 0.8052681091225925, 'f1': 0.740698004836761, 'auc': 0.8027365777646627, 'prauc': 0.8124239430228842}\n",
      "Test:      {'precision': 0.6838487972490515, 'recall': 0.8112260896807425, 'f1': 0.7421112973864309, 'auc': 0.8048231103406724, 'prauc': 0.8207017070610059}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 004: 100%|██████████| 98/98 [00:03<00:00, 29.12it/s, loss=0.5261]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 54.48it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 54.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.768432355043778, 'recall': 0.6732518030709526, 'f1': 0.717700145445602, 'auc': 0.8118998150181621, 'prauc': 0.8236194613917156}\n",
      "Test:      {'precision': 0.7713371265975415, 'recall': 0.6801505174014421, 'f1': 0.7228795150973112, 'auc': 0.8153434231937937, 'prauc': 0.8300476992008331}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 005: 100%|██████████| 98/98 [00:03<00:00, 28.88it/s, loss=0.4930]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 53.64it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 54.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7342589602817751, 'recall': 0.7130761994333237, 'f1': 0.7235125626093322, 'auc': 0.8002231316417406, 'prauc': 0.8038555837646456}\n",
      "Test:      {'precision': 0.7306472081195093, 'recall': 0.7221699592326053, 'f1': 0.7263838461254616, 'auc': 0.8033905172626409, 'prauc': 0.813726242839385}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 006: 100%|██████████| 98/98 [00:03<00:00, 29.32it/s, loss=0.4639]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 54.62it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 54.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.715382253605418, 'recall': 0.7306365631836607, 'f1': 0.7229289431832343, 'auc': 0.7973586309635945, 'prauc': 0.8090624763752505}\n",
      "Test:      {'precision': 0.7158590308347519, 'recall': 0.7133897773574369, 'f1': 0.7146222660830538, 'auc': 0.788799932754397, 'prauc': 0.806624946189753}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 007: 100%|██████████| 98/98 [00:03<00:00, 29.25it/s, loss=0.4335]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 50.66it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 54.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7530446549365594, 'recall': 0.6980244590758921, 'f1': 0.7244914514735044, 'auc': 0.8101902577035828, 'prauc': 0.8177918596081881}\n",
      "Test:      {'precision': 0.7455581629207323, 'recall': 0.6973973032276658, 'f1': 0.7206740066688213, 'auc': 0.8083316597432888, 'prauc': 0.8189561623507442}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 008: 100%|██████████| 98/98 [00:03<00:00, 29.13it/s, loss=0.4090]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 54.37it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 52.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.6549988012451331, 'recall': 0.8566948886771506, 'f1': 0.7423912994348185, 'auc': 0.80840393860303, 'prauc': 0.820129507253571}\n",
      "Test:      {'precision': 0.6594412331390669, 'recall': 0.8585763562218295, 'f1': 0.7459474136918293, 'auc': 0.8109254978112462, 'prauc': 0.8214286962675373}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 009: 100%|██████████| 98/98 [00:03<00:00, 29.14it/s, loss=0.3825]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 55.19it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 54.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7025741466124719, 'recall': 0.7873941674481424, 'f1': 0.7425698604583373, 'auc': 0.8110702552198769, 'prauc': 0.8141630057252044}\n",
      "Test:      {'precision': 0.7101901788228493, 'recall': 0.784571966131124, 'f1': 0.745530388335547, 'auc': 0.8112741078758392, 'prauc': 0.8183374981469732}\n",
      "\n",
      "Early stopping triggered (no improvement for 5 epochs).\n",
      "\n",
      "Best validation performance:\n",
      "{'precision': 0.768432355043778, 'recall': 0.6732518030709526, 'f1': 0.717700145445602, 'auc': 0.8118998150181621, 'prauc': 0.8236194613917156}\n",
      "Corresponding test performance:\n",
      "{'precision': 0.7713371265975415, 'recall': 0.6801505174014421, 'f1': 0.7228795150973112, 'auc': 0.8153434231937937, 'prauc': 0.8300476992008331}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 001: 100%|██████████| 98/98 [00:03<00:00, 29.52it/s, loss=0.6734]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 55.29it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 55.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.820526893519097, 'recall': 0.4687989965491728, 'f1': 0.596687283336191, 'auc': 0.7762435635393172, 'prauc': 0.7807777693245315}\n",
      "Test:      {'precision': 0.7942534633104451, 'recall': 0.4854186265271702, 'f1': 0.6025690883211855, 'auc': 0.7670400408305638, 'prauc': 0.7760180780521471}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 002: 100%|██████████| 98/98 [00:03<00:00, 29.38it/s, loss=0.5985]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 55.20it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 50.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7199131513625313, 'recall': 0.7278143618666422, 'f1': 0.7238421905382004, 'auc': 0.7925342933781204, 'prauc': 0.8009219052379647}\n",
      "Test:      {'precision': 0.7072578196152225, 'recall': 0.7303229852595474, 'f1': 0.71860536371243, 'auc': 0.7883768793912864, 'prauc': 0.8014335812474234}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 003: 100%|██████████| 98/98 [00:03<00:00, 28.84it/s, loss=0.5678]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 52.96it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 55.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7346128391769206, 'recall': 0.6961429915312132, 'f1': 0.7148607259625107, 'auc': 0.7946769418948445, 'prauc': 0.8067465746629442}\n",
      "Test:      {'precision': 0.7223642172500884, 'recall': 0.7089996864198527, 'f1': 0.7156195550551422, 'auc': 0.7879594130505797, 'prauc': 0.8031006864678859}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 004: 100%|██████████| 98/98 [00:03<00:00, 29.42it/s, loss=0.5372]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 55.09it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 54.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.622670807452035, 'recall': 0.8802132329856375, 'f1': 0.7293750763454032, 'auc': 0.7871301732194003, 'prauc': 0.802245796289836}\n",
      "Test:      {'precision': 0.6170921198654449, 'recall': 0.8717466290345822, 'f1': 0.7226410141202244, 'auc': 0.7802454967844421, 'prauc': 0.8005303325835422}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 005: 100%|██████████| 98/98 [00:03<00:00, 29.42it/s, loss=0.5135]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 55.11it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 54.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7969957081510859, 'recall': 0.5823142050781364, 'f1': 0.67294799294438, 'auc': 0.8031219440344287, 'prauc': 0.8117493164972686}\n",
      "Test:      {'precision': 0.7876741240996722, 'recall': 0.5851364063951549, 'f1': 0.6714645507019549, 'auc': 0.7965672529013508, 'prauc': 0.8076525361063002}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 006: 100%|██████████| 98/98 [00:03<00:00, 29.12it/s, loss=0.4801]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 54.15it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 52.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7657819225223609, 'recall': 0.6694888679815946, 'f1': 0.7144052150301538, 'auc': 0.8067954576715517, 'prauc': 0.8129107310637826}\n",
      "Test:      {'precision': 0.7546638507541195, 'recall': 0.6723110692986131, 'f1': 0.7111111061254056, 'auc': 0.8013258356499343, 'prauc': 0.8084475070496911}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 007: 100%|██████████| 98/98 [00:03<00:00, 25.99it/s, loss=0.4546]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 53.65it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 55.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.6886543535601882, 'recall': 0.8184383819353451, 'f1': 0.7479581552298062, 'auc': 0.8147179973935155, 'prauc': 0.8274859412071645}\n",
      "Test:      {'precision': 0.6858475894227946, 'recall': 0.8297271872034189, 'f1': 0.7509578494490613, 'auc': 0.8124652006521214, 'prauc': 0.8252185583546638}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 008: 100%|██████████| 98/98 [00:03<00:00, 29.16it/s, loss=0.4145]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 54.87it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 55.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.6967418546346512, 'recall': 0.784571966131124, 'f1': 0.7380530923605333, 'auc': 0.8111487250560617, 'prauc': 0.8212226861935757}\n",
      "Test:      {'precision': 0.6957823129232769, 'recall': 0.8018187519573478, 'f1': 0.7450466150695154, 'auc': 0.8114738816769322, 'prauc': 0.8191870629340979}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 009: 100%|██████████| 98/98 [00:03<00:00, 29.70it/s, loss=0.3985]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 55.38it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 55.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7153511497802506, 'recall': 0.7218563813084922, 'f1': 0.7185890382318223, 'auc': 0.7881980562589541, 'prauc': 0.8045257496234766}\n",
      "Test:      {'precision': 0.7049332919618215, 'recall': 0.7124490435850974, 'f1': 0.7086712364202633, 'auc': 0.7805904325009676, 'prauc': 0.7990685367729256}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 010: 100%|██████████| 98/98 [00:03<00:00, 29.07it/s, loss=0.3651]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 54.79it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 53.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.6964438122313046, 'recall': 0.7676387582290134, 'f1': 0.7303102575394775, 'auc': 0.7990723579301605, 'prauc': 0.8081743397908485}\n",
      "Test:      {'precision': 0.6909191891122163, 'recall': 0.7801818751935398, 'f1': 0.7328424103328924, 'auc': 0.7923351085971189, 'prauc': 0.8007272773248102}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 011: 100%|██████████| 98/98 [00:03<00:00, 29.58it/s, loss=0.3252]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 51.22it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 54.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.6390909090894566, 'recall': 0.8817811226062033, 'f1': 0.741072600211674, 'auc': 0.8041555153594405, 'prauc': 0.8165573356650647}\n",
      "Test:      {'precision': 0.634353361624672, 'recall': 0.8905613044813717, 'f1': 0.7409339893995821, 'auc': 0.7999896816252899, 'prauc': 0.8125217522362662}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 012: 100%|██████████| 98/98 [00:03<00:00, 29.17it/s, loss=0.3178]\n",
      "Running inference: 100%|██████████| 198/198 [00:03<00:00, 55.18it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:03<00:00, 55.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7015225509890792, 'recall': 0.7657572906843344, 'f1': 0.7322338780658579, 'auc': 0.7965539886036881, 'prauc': 0.8036118574028495}\n",
      "Test:      {'precision': 0.6876560332851938, 'recall': 0.7773596738765213, 'f1': 0.7297615493292263, 'auc': 0.7954460734054211, 'prauc': 0.7999740964043472}\n",
      "\n",
      "Early stopping triggered (no improvement for 5 epochs).\n",
      "\n",
      "Best validation performance:\n",
      "{'precision': 0.6886543535601882, 'recall': 0.8184383819353451, 'f1': 0.7479581552298062, 'auc': 0.8147179973935155, 'prauc': 0.8274859412071645}\n",
      "Corresponding test performance:\n",
      "{'precision': 0.6858475894227946, 'recall': 0.8297271872034189, 'f1': 0.7509578494490613, 'auc': 0.8124652006521214, 'prauc': 0.8252185583546638}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final_metrics = {\"precision\":[],\"recall\":[],\"f1\":[],\"auc\":[],\"prauc\":[]}\n",
    "for i in range(5):\n",
    "    model = HeteroGT(tokenizer, d_model=128, num_heads=4, layer_types=['gnn', 'tf', 'tf'], max_num_adms=config.max_num_adms, \n",
    "                     device=device, task=curr_task, label_vocab_size=config.label_vocab_size).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.lr)\n",
    "    best_test_metric = train_with_early_stopping(model, train_dataloader, val_dataloader, test_dataloader,\n",
    "                                             optimizer, loss_fn, device, config.early_stop_patience, task_type, config.epochs, \n",
    "                                             val_long_seq_idx=None, test_long_seq_idx=None, eval_metric=eval_metric, return_model=False)\n",
    "    for key in final_metrics.keys():\n",
    "        final_metrics[key].append(best_test_metric[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d169eb3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Metrics:\n",
      "precision: 0.7329 ± 0.0321\n",
      "recall: 0.7644 ± 0.0553\n",
      "f1: 0.7458 ± 0.0131\n",
      "auc: 0.8206 ± 0.0079\n",
      "prauc: 0.8335 ± 0.0065\n"
     ]
    }
   ],
   "source": [
    "# print the mean and std of the final metrics\n",
    "print(\"\\nFinal Metrics:\")\n",
    "for key in final_metrics.keys():\n",
    "    mean_value = np.mean(final_metrics[key])\n",
    "    std_value = np.std(final_metrics[key])\n",
    "    print(f\"{key}: {mean_value:.4f} ± {std_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fed5f6-b245-4bc3-b252-f6af0756f18a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 001: 100%|██████████| 98/98 [00:01<00:00, 66.36it/s, loss=0.6820]\n",
      "Running inference: 100%|██████████| 198/198 [00:00<00:00, 219.51it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:00<00:00, 219.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7802152317848501, 'recall': 0.5910943869533049, 'f1': 0.6726137328268653, 'auc': 0.7779310669114603, 'prauc': 0.7777426134816886}\n",
      "Test:      {'precision': 0.772115776596934, 'recall': 0.5939165882703232, 'f1': 0.6713931180887326, 'auc': 0.773911977720364, 'prauc': 0.7720519788630555}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 002: 100%|██████████| 98/98 [00:01<00:00, 67.90it/s, loss=0.5837]\n",
      "Running inference: 100%|██████████| 198/198 [00:00<00:00, 222.25it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:00<00:00, 219.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.8650234741733274, 'recall': 0.4622138601427965, 'f1': 0.6024933533162475, 'auc': 0.7981641775853777, 'prauc': 0.8051068662292509}\n",
      "Test:      {'precision': 0.8506711409348396, 'recall': 0.4769520225761149, 'f1': 0.6112115686306304, 'auc': 0.7929814918557825, 'prauc': 0.7995481641001062}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 003: 100%|██████████| 98/98 [00:01<00:00, 66.75it/s, loss=0.5502]\n",
      "Running inference: 100%|██████████| 198/198 [00:00<00:00, 216.96it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:00<00:00, 217.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.840271055175023, 'recall': 0.5443712762604441, 'f1': 0.6607040865674061, 'auc': 0.8133547221409223, 'prauc': 0.8272673851986445}\n",
      "Test:      {'precision': 0.829166666662828, 'recall': 0.5616180620866679, 'f1': 0.6696578751600978, 'auc': 0.8107038289223539, 'prauc': 0.8240000547074331}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 004: 100%|██████████| 98/98 [00:01<00:00, 65.78it/s, loss=0.5214]\n",
      "Running inference: 100%|██████████| 198/198 [00:00<00:00, 212.63it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:00<00:00, 208.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7975308641942489, 'recall': 0.6077140169313022, 'f1': 0.6898024510417909, 'auc': 0.8099723808280809, 'prauc': 0.8213436696103045}\n",
      "Test:      {'precision': 0.7895990472378341, 'recall': 0.6237064910610733, 'f1': 0.6969166033355435, 'auc': 0.8103293977542183, 'prauc': 0.8196388109068522}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 005: 100%|██████████| 98/98 [00:01<00:00, 66.75it/s, loss=0.4868]\n",
      "Running inference: 100%|██████████| 198/198 [00:00<00:00, 209.64it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:00<00:00, 208.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.8006535947679713, 'recall': 0.6146127312617917, 'f1': 0.6954053525435737, 'auc': 0.8075939209086345, 'prauc': 0.817452171528826}\n",
      "Test:      {'precision': 0.78876582278169, 'recall': 0.6252743806816392, 'f1': 0.6975686499533276, 'auc': 0.8032812431577849, 'prauc': 0.8148629490349683}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 006: 100%|██████████| 98/98 [00:01<00:00, 64.94it/s, loss=0.4714]\n",
      "Running inference: 100%|██████████| 198/198 [00:00<00:00, 210.89it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:00<00:00, 216.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7460875119746213, 'recall': 0.7325180307283395, 'f1': 0.7392405013271958, 'auc': 0.8184862073438322, 'prauc': 0.8233309445337794}\n",
      "Test:      {'precision': 0.7379695746639616, 'recall': 0.745374725616979, 'f1': 0.7416536611444564, 'auc': 0.8158878810437362, 'prauc': 0.8214888690273356}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 007: 100%|██████████| 98/98 [00:01<00:00, 66.49it/s, loss=0.4525]\n",
      "Running inference: 100%|██████████| 198/198 [00:00<00:00, 220.96it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:00<00:00, 220.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7644429160909063, 'recall': 0.6970837253035526, 'f1': 0.7292110824282713, 'auc': 0.8185115266763784, 'prauc': 0.8285470141333441}\n",
      "Test:      {'precision': 0.754742096503312, 'recall': 0.7111947318886448, 'f1': 0.7323215965519346, 'auc': 0.8153599325933297, 'prauc': 0.8246691229212939}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 008: 100%|██████████| 98/98 [00:01<00:00, 67.06it/s, loss=0.4189]\n",
      "Running inference: 100%|██████████| 198/198 [00:00<00:00, 220.63it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:00<00:00, 218.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7272182254174844, 'recall': 0.7607400438985239, 'f1': 0.7436015275673084, 'auc': 0.8162918149530551, 'prauc': 0.8214974615291964}\n",
      "Test:      {'precision': 0.7241379310323486, 'recall': 0.7704609595460318, 'f1': 0.7465815811465638, 'auc': 0.8173869143881933, 'prauc': 0.8201820226348031}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 009: 100%|██████████| 98/98 [00:01<00:00, 66.00it/s, loss=0.4124]\n",
      "Running inference: 100%|██████████| 198/198 [00:00<00:00, 217.94it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:00<00:00, 218.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7544889502736378, 'recall': 0.6851677641872526, 'f1': 0.7181594033904978, 'auc': 0.8069147197657279, 'prauc': 0.8092984934584941}\n",
      "Test:      {'precision': 0.7524752475221834, 'recall': 0.6911257447454026, 'f1': 0.7204968894166128, 'auc': 0.8046008374493582, 'prauc': 0.8091342648953093}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 010: 100%|██████████| 98/98 [00:01<00:00, 66.47it/s, loss=0.3798]\n",
      "Running inference: 100%|██████████| 198/198 [00:00<00:00, 221.14it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:00<00:00, 218.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.741121495324794, 'recall': 0.7460018814652054, 'f1': 0.7435536752602709, 'auc': 0.8177198454033706, 'prauc': 0.8216753949267185}\n",
      "Test:      {'precision': 0.7309815950897823, 'recall': 0.747256193161658, 'f1': 0.7390293018675963, 'auc': 0.8128063110199737, 'prauc': 0.816905717321505}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 011: 100%|██████████| 98/98 [00:01<00:00, 66.31it/s, loss=0.3739]\n",
      "Running inference: 100%|██████████| 198/198 [00:00<00:00, 221.23it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:00<00:00, 220.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7452768729617418, 'recall': 0.7174662903709079, 'f1': 0.7311072006233729, 'auc': 0.8119561304383691, 'prauc': 0.8134965575598239}\n",
      "Test:      {'precision': 0.7346809854683048, 'recall': 0.729382251487208, 'f1': 0.7320220248954802, 'auc': 0.8115890448054031, 'prauc': 0.8151821380009914}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 012: 100%|██████████| 98/98 [00:01<00:00, 66.76it/s, loss=0.3422]\n",
      "Running inference: 100%|██████████| 198/198 [00:00<00:00, 222.20it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:00<00:00, 219.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7174366616968184, 'recall': 0.7547820633403739, 'f1': 0.7356356918224851, 'auc': 0.8050714824037171, 'prauc': 0.8027855614720343}\n",
      "Test:      {'precision': 0.7159024956450496, 'recall': 0.7735967387871634, 'f1': 0.7436322482079729, 'auc': 0.8084618222652405, 'prauc': 0.8084965501652762}\n",
      "\n",
      "Early stopping triggered (no improvement for 5 epochs).\n",
      "\n",
      "Best validation performance:\n",
      "{'precision': 0.7644429160909063, 'recall': 0.6970837253035526, 'f1': 0.7292110824282713, 'auc': 0.8185115266763784, 'prauc': 0.8285470141333441}\n",
      "Corresponding test performance:\n",
      "{'precision': 0.754742096503312, 'recall': 0.7111947318886448, 'f1': 0.7323215965519346, 'auc': 0.8153599325933297, 'prauc': 0.8246691229212939}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 001: 100%|██████████| 98/98 [00:01<00:00, 67.62it/s, loss=0.6741]\n",
      "Running inference: 100%|██████████| 198/198 [00:00<00:00, 220.55it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:00<00:00, 219.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7259598450132936, 'recall': 0.6462841015972208, 'f1': 0.6838088868526764, 'auc': 0.7751152456643406, 'prauc': 0.7838679989813095}\n",
      "Test:      {'precision': 0.7199585635334256, 'recall': 0.6538099717759367, 'f1': 0.6852916959132024, 'auc': 0.776751795774701, 'prauc': 0.7861070587887498}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 002: 100%|██████████| 98/98 [00:01<00:00, 65.80it/s, loss=0.5865]\n",
      "Running inference: 100%|██████████| 198/198 [00:00<00:00, 220.47it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:00<00:00, 217.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.6677792041061161, 'recall': 0.8156161806183267, 'f1': 0.7343308815523883, 'auc': 0.796995117689181, 'prauc': 0.8081394804005039}\n",
      "Test:      {'precision': 0.6679457661789001, 'recall': 0.8187519598594584, 'f1': 0.7357001922880332, 'auc': 0.7971154354328962, 'prauc': 0.808823175244052}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 003: 100%|██████████| 98/98 [00:01<00:00, 66.46it/s, loss=0.5492]\n",
      "Running inference: 100%|██████████| 198/198 [00:00<00:00, 216.04it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:00<00:00, 217.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.641978175062359, 'recall': 0.8670429601728848, 'f1': 0.7377267827293187, 'auc': 0.7991972967794512, 'prauc': 0.810105479426211}\n",
      "Test:      {'precision': 0.6374885426199874, 'recall': 0.8723737848828085, 'f1': 0.7366609245510691, 'auc': 0.7919851898606113, 'prauc': 0.8049538638959202}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 004: 100%|██████████| 98/98 [00:01<00:00, 67.74it/s, loss=0.5147]\n",
      "Running inference: 100%|██████████| 198/198 [00:00<00:00, 216.25it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:00<00:00, 213.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7775297619018693, 'recall': 0.6553778613965024, 'f1': 0.7112472300177507, 'auc': 0.8132043634855437, 'prauc': 0.8232223119410809}\n",
      "Test:      {'precision': 0.7679355783280822, 'recall': 0.6578864847894077, 'f1': 0.7086640720414102, 'auc': 0.8093351091004541, 'prauc': 0.8195537149559171}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 005: 100%|██████████| 98/98 [00:01<00:00, 65.63it/s, loss=0.4919]\n",
      "Running inference: 100%|██████████| 198/198 [00:00<00:00, 211.01it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:00<00:00, 208.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.721025043678739, 'recall': 0.7764189401041819, 'f1': 0.7476974130930639, 'auc': 0.8167343506681339, 'prauc': 0.824928908386181}\n",
      "Test:      {'precision': 0.7182608695631355, 'recall': 0.7770460959524081, 'f1': 0.7464979615667079, 'auc': 0.8116592600869662, 'prauc': 0.8166648163365459}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 006: 100%|██████████| 98/98 [00:01<00:00, 68.02it/s, loss=0.4568]\n",
      "Running inference: 100%|██████████| 198/198 [00:00<00:00, 220.78it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:00<00:00, 219.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.752027448531653, 'recall': 0.7560363750368265, 'f1': 0.7540265782658554, 'auc': 0.8267224757002227, 'prauc': 0.8342930295772399}\n",
      "Test:      {'precision': 0.7443445924984681, 'recall': 0.753214173719808, 'f1': 0.7487531122048239, 'auc': 0.8255206626711906, 'prauc': 0.8352043650364971}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 007: 100%|██████████| 98/98 [00:01<00:00, 67.11it/s, loss=0.4160]\n",
      "Running inference: 100%|██████████| 198/198 [00:00<00:00, 221.52it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:00<00:00, 218.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7532552083308813, 'recall': 0.72561931639785, 'f1': 0.7391790398803944, 'auc': 0.8200268686345615, 'prauc': 0.8269643867687336}\n",
      "Test:      {'precision': 0.7467220978549833, 'recall': 0.7322044528042264, 'f1': 0.7393920152641317, 'auc': 0.8173650696339292, 'prauc': 0.8240164572747245}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 008: 100%|██████████| 98/98 [00:01<00:00, 66.76it/s, loss=0.3979]\n",
      "Running inference: 100%|██████████| 198/198 [00:00<00:00, 220.50it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:00<00:00, 216.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7954722872724611, 'recall': 0.6390718093426182, 'f1': 0.7087463000474036, 'auc': 0.8243731531079128, 'prauc': 0.8265064322153706}\n",
      "Test:      {'precision': 0.7856609409978131, 'recall': 0.6597679523340867, 'f1': 0.717231970491425, 'auc': 0.8190249186232569, 'prauc': 0.8226607666809336}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 009: 100%|██████████| 98/98 [00:01<00:00, 67.32it/s, loss=0.3694]\n",
      "Running inference: 100%|██████████| 198/198 [00:00<00:00, 221.98it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:00<00:00, 220.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7176870748278977, 'recall': 0.7939793038545188, 'f1': 0.7539079896509554, 'auc': 0.818451493735123, 'prauc': 0.8250984976522793}\n",
      "Test:      {'precision': 0.7093513058109819, 'recall': 0.7920978363098398, 'f1': 0.7484444394574131, 'auc': 0.8130015044693664, 'prauc': 0.81696409569918}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 010: 100%|██████████| 98/98 [00:01<00:00, 67.40it/s, loss=0.3416]\n",
      "Running inference: 100%|██████████| 198/198 [00:00<00:00, 220.53it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:00<00:00, 219.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.6481394253399714, 'recall': 0.8629664471594137, 'f1': 0.7402824429807047, 'auc': 0.8044736648297088, 'prauc': 0.8169446044716173}\n",
      "Test:      {'precision': 0.6533553875220857, 'recall': 0.8670429601728848, 'f1': 0.7451825850442056, 'auc': 0.8097731115235105, 'prauc': 0.8169796908696796}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 011: 100%|██████████| 98/98 [00:01<00:00, 66.98it/s, loss=0.3175]\n",
      "Running inference:  34%|███▍      | 68/198 [00:00<00:00, 225.15it/s]"
     ]
    }
   ],
   "source": [
    "final_metrics = {\"precision\":[],\"recall\":[],\"f1\":[],\"auc\":[],\"prauc\":[]}\n",
    "for i in range(5):\n",
    "    model = HeteroGT(tokenizer, d_model=128, num_heads=4, layer_types=['tf', 'tf'], max_num_adms=config.max_num_adms, \n",
    "                     device=device, task=curr_task, label_vocab_size=config.label_vocab_size).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.lr)\n",
    "    best_test_metric = train_with_early_stopping(model, train_dataloader, val_dataloader, test_dataloader,\n",
    "                                             optimizer, loss_fn, device, config.early_stop_patience, task_type, config.epochs, \n",
    "                                             val_long_seq_idx=None, test_long_seq_idx=None, eval_metric=eval_metric, return_model=False)\n",
    "    for key in final_metrics.keys():\n",
    "        final_metrics[key].append(best_test_metric[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12dd11d-4936-466a-9a97-e10f223539fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print the mean and std of the final metrics\n",
    "print(\"\\nFinal Metrics:\")\n",
    "for key in final_metrics.keys():\n",
    "    mean_value = np.mean(final_metrics[key])\n",
    "    std_value = np.std(final_metrics[key])\n",
    "    print(f\"{key}: {mean_value:.4f} ± {std_value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heart-cuda",
   "language": "python",
   "name": "heart-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
